program: train_transformer_fine_tuning.py
method: grid
metric:
  goal: maximize
  name: dev_score
parameters:
  embeddings:
    values: [ bert-base-uncased, distilbert-base-uncased, roberta-base ]
  learning_rate:
    values: [5e-5, 3e-5, 2e-5]
  mini_batch_size:
    values: [16, 32]
  max_epochs:
    values: [2, 3, 4]
  dropout:
    values: [0.0, 0.05, 0.1, 0.25, 0.5]
  word_dropout:
    values: [0.0, 0.05, 0.1, 0.25, 0.5]
  locked_dropout:
    values: [0.0, 0.05, 0.1, 0.25, 0.5]
command:
  - ${env}
  - python3
  - ${program}
  - ${args}